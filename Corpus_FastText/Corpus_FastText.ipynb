{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449b230c",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17deaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1e724",
   "metadata": {},
   "source": [
    "# Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475a22d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the desperate hour lakewood salah cerita suara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edisi males review singkat tonton libur dp des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plot utama orang deserter pursuit buru wamil j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film hereditary horror thrill midsommar gatau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batman manusiawi tarung nya sadis scene pursui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tokens_\n",
       "0  the desperate hour lakewood salah cerita suara...\n",
       "1  edisi males review singkat tonton libur dp des...\n",
       "2  plot utama orang deserter pursuit buru wamil j...\n",
       "3  film hereditary horror thrill midsommar gatau ...\n",
       "4  batman manusiawi tarung nya sadis scene pursui..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset\n",
    "tweet_df = pd.read_pickle(r'C:\\Users\\HP Victus 16\\Documents\\TA_Code\\Preprocessing\\preprocessed_df.pkl')\n",
    "tweet_df = pd.DataFrame(tweet_df['detokenize'])\n",
    "tweet_df = tweet_df.rename(columns={'detokenize': 'tokens_'})\n",
    "tweet_df = tweet_df.drop_duplicates(subset='tokens_', keep='first').reset_index(drop=True)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72446a58",
   "metadata": {},
   "source": [
    "# Tokenizing Tweet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ed12d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing Tweet Data : 100%|██████████████████████████████████████████████████| 17116/17116 [00:01<00:00, 9330.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[the, desperate, hour, lakewood, salah, cerita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[edisi, males, review, singkat, tonton, libur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[plot, utama, orang, deserter, pursuit, buru, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[film, hereditary, horror, thrill, midsommar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[batman, manusiawi, tarung, nya, sadis, scene,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tokens_\n",
       "0  [the, desperate, hour, lakewood, salah, cerita...\n",
       "1  [edisi, males, review, singkat, tonton, libur,...\n",
       "2  [plot, utama, orang, deserter, pursuit, buru, ...\n",
       "3  [film, hereditary, horror, thrill, midsommar, ...\n",
       "4  [batman, manusiawi, tarung, nya, sadis, scene,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenizing(data):\n",
    "    return nltk.tokenize.word_tokenize(data)\n",
    "\n",
    "tqdm.pandas(desc=\"Tokenizing Tweet Data : \")\n",
    "tweet_df['tokens_'] = tweet_df['tokens_'].astype(str).progress_apply(tokenizing)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0976c",
   "metadata": {},
   "source": [
    "# Tweet Corpus FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b022c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tweet = FastText(sentences=tweet_df['tokens_'], window=4, min_count=1, workers=6)\n",
    "\n",
    "model_tweet.save(\"fasttext_tweet.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b239881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cinematografi', 0.9991486072540283),\n",
       " ('sinematografis', 0.9986787438392639),\n",
       " ('fotografi', 0.9981692433357239),\n",
       " ('sinematography', 0.9974574446678162),\n",
       " ('pornografi', 0.9970502257347107),\n",
       " ('filmografi', 0.9955441951751709),\n",
       " ('cinematograpy', 0.9953588247299194),\n",
       " ('sinematografer', 0.9952602386474609),\n",
       " ('fotografik', 0.9936928153038025),\n",
       " ('visual', 0.9936772584915161)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tweet = FastText.load(\"fasttext_tweet.model\")\n",
    "\n",
    "ft = model_tweet.wv\n",
    "\n",
    "ft.most_similar('sinematografi', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789bd8d",
   "metadata": {},
   "source": [
    "# News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52192b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jakarta wakil gubernur daerah khusus ibukota j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jakarta badan awas milu daerah khusus ibukota ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jakarta wakil ketua komisi ix dewan perwakilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jakarta pasang calon nomor urut tiga anies bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jakarta rumah partai golkar sedikit guncang uj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tokens_\n",
       "0  jakarta wakil gubernur daerah khusus ibukota j...\n",
       "1  jakarta badan awas milu daerah khusus ibukota ...\n",
       "2  jakarta wakil ketua komisi ix dewan perwakilan...\n",
       "3  jakarta pasang calon nomor urut tiga anies bas...\n",
       "4  jakarta rumah partai golkar sedikit guncang uj..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset\n",
    "news_df = pd.read_csv(r'C:\\Users\\HP Victus 16\\Documents\\TA_Code\\Dataset\\indonews-clean.csv')\n",
    "news_df = news_df[['clean_data']].copy(deep=True)\n",
    "news_df = news_df.rename(columns={'clean_data': 'tokens_'})\n",
    "news_df = news_df.drop_duplicates(subset='tokens_', keep='first').reset_index(drop=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7880b17",
   "metadata": {},
   "source": [
    "# Tokenizing News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb5f6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing News Data : 100%|█████████████████████████████████████████████████| 140890/140890 [01:15<00:00, 1871.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jakarta, wakil, gubernur, daerah, khusus, ibu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[jakarta, badan, awas, milu, daerah, khusus, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[jakarta, wakil, ketua, komisi, ix, dewan, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jakarta, pasang, calon, nomor, urut, tiga, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jakarta, rumah, partai, golkar, sedikit, gunc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tokens_\n",
       "0  [jakarta, wakil, gubernur, daerah, khusus, ibu...\n",
       "1  [jakarta, badan, awas, milu, daerah, khusus, i...\n",
       "2  [jakarta, wakil, ketua, komisi, ix, dewan, per...\n",
       "3  [jakarta, pasang, calon, nomor, urut, tiga, an...\n",
       "4  [jakarta, rumah, partai, golkar, sedikit, gunc..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['tokens_'] = news_df['tokens_'].apply(str)\n",
    "news_df['tokens_'] = news_df['tokens_'].astype(np.uint8,errors='ignore')\n",
    "\n",
    "tqdm.pandas(desc=\"Tokenizing News Data : \")\n",
    "news_df['tokens_'] = news_df['tokens_'].progress_apply(tokenizing)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de460069",
   "metadata": {},
   "source": [
    "# News Corpus FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b18c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_news = FastText(sentences=news_df['tokens_'], window=4, min_count=1, workers=6)\n",
    "\n",
    "model_news.save(\"fasttext_news.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe85340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filmfilm', 0.9886583685874939),\n",
       " ('mfilm', 0.9735487103462219),\n",
       " ('aadcfilm', 0.9573121070861816),\n",
       " ('filmkubo', 0.9388416409492493),\n",
       " ('rsfilm', 0.9371312260627747),\n",
       " ('filmjoy', 0.9197675585746765),\n",
       " ('filmn', 0.9083369374275208),\n",
       " ('filma', 0.9066123366355896),\n",
       " ('films', 0.905907392501831),\n",
       " ('mimefilm', 0.8948878049850464)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_news = FastText.load(\"fasttext_news.model\")\n",
    "\n",
    "ft = model_news.wv\n",
    "\n",
    "ft.most_similar('film', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af180a5b",
   "metadata": {},
   "source": [
    "# Concatenate Two Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c2296d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jakarta, wakil, gubernur, daerah, khusus, ibu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[jakarta, badan, awas, milu, daerah, khusus, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[jakarta, wakil, ketua, komisi, ix, dewan, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jakarta, pasang, calon, nomor, urut, tiga, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jakarta, rumah, partai, golkar, sedikit, gunc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              merged\n",
       "0  [jakarta, wakil, gubernur, daerah, khusus, ibu...\n",
       "1  [jakarta, badan, awas, milu, daerah, khusus, i...\n",
       "2  [jakarta, wakil, ketua, komisi, ix, dewan, per...\n",
       "3  [jakarta, pasang, calon, nomor, urut, tiga, an...\n",
       "4  [jakarta, rumah, partai, golkar, sedikit, gunc..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([news_df, tweet_df])\n",
    "df = df.rename(columns={'tokens_': 'merged'})\n",
    "df['merged'] = df['merged'].astype(np.uint8,errors='ignore')\n",
    "df['merged'].reset_index(drop=True,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654130d7",
   "metadata": {},
   "source": [
    "# News + Tweet Corpus FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65dbbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conc = FastText(sentences=df['merged'], window=4, min_count=1, workers=6)\n",
    "\n",
    "model_conc.save(\"fasttext_news_tweet.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b61ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tanskrip', 0.8184252977371216),\n",
       " ('skripsi', 0.7843674421310425),\n",
       " ('skripochka', 0.7686924934387207),\n",
       " ('enskripsi', 0.7673084139823914),\n",
       " ('skript', 0.745566189289093),\n",
       " ('skrit', 0.732649028301239),\n",
       " ('deskripsiin', 0.7300468683242798),\n",
       " ('traskrip', 0.7249947786331177),\n",
       " ('transkrip', 0.7214085459709167),\n",
       " ('munuskrip', 0.716574490070343),\n",
       " ('manuskrip', 0.699177086353302),\n",
       " ('deskripsi', 0.689950704574585),\n",
       " ('dienskripsi', 0.6833628416061401),\n",
       " ('inskripsi', 0.6783464550971985),\n",
       " ('makrip', 0.677362322807312),\n",
       " ('begrip', 0.677038848400116),\n",
       " ('terenskripsi', 0.6664600372314453),\n",
       " ('skr', 0.6575965881347656),\n",
       " ('alrip', 0.654687225818634),\n",
       " ('dienkrip', 0.6442853808403015),\n",
       " ('scriptnya', 0.6367748379707336),\n",
       " ('sketsa', 0.6353818774223328),\n",
       " ('skrg', 0.6351134777069092),\n",
       " ('transkripsi', 0.6341580152511597),\n",
       " ('naskah', 0.6323281526565552),\n",
       " ('scripnya', 0.62846440076828),\n",
       " ('mendeskripskannya', 0.620667576789856),\n",
       " ('skrd', 0.6196370124816895),\n",
       " ('dokumentar', 0.6168381571769714),\n",
       " ('draftnya', 0.6133556365966797),\n",
       " ('membuatskripsi', 0.611599862575531),\n",
       " ('drip', 0.6112372279167175),\n",
       " ('smenulis', 0.6087672114372253),\n",
       " ('formulis', 0.6076120734214783),\n",
       " ('diterjemahin', 0.6066344380378723),\n",
       " ('sampul', 0.6031919717788696),\n",
       " ('dokumentator', 0.6014475226402283),\n",
       " ('skip', 0.6001657843589783),\n",
       " ('inkripsi', 0.5999836325645447),\n",
       " ('gambar', 0.5992343425750732)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conc = FastText.load(\"fasttext_news_tweet.model\")\n",
    "\n",
    "ft = model_conc.wv\n",
    "\n",
    "ft.most_similar('skrip', topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887dddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
