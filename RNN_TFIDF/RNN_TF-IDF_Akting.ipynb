{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952a8e9a",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7d2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, SimpleRNN, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51221a6e",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a1552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detokenize</th>\n",
       "      <th>akting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the desperate hour lakewood salah cerita suara...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edisi males review singkat tonton libur dp des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plot utama orang deserter pursuit buru wamil j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>film hereditary horror thrill midsommar gatau ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batman manusiawi tarung nya sadis scene pursui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          detokenize  akting\n",
       "0  the desperate hour lakewood salah cerita suara...       1\n",
       "1  edisi males review singkat tonton libur dp des...       1\n",
       "2  plot utama orang deserter pursuit buru wamil j...       1\n",
       "3  film hereditary horror thrill midsommar gatau ...       0\n",
       "4  batman manusiawi tarung nya sadis scene pursui...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(r'C:\\Users\\HP Victus 16\\Documents\\TA_Code\\Preprocessing\\preprocessed_df.pkl')\n",
    "df = pd.DataFrame(df[['detokenize','akting']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68117200",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['detokenize'].astype(str)\n",
    "label = pd.get_dummies(df['akting']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff6732",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d427b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAX_FEATURES = 10000\n",
    "test_size_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e39ee4",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3db659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\t| X shape: (12072,)\tY shape: (12072, 3)\n",
      "Test\t| X shape: (5175,)\tY shape: (5175, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = (\n",
    "    train_test_split(reviews, \n",
    "                     label, \n",
    "                     test_size=test_size_split, \n",
    "                     stratify = label, \n",
    "                     random_state=42)\n",
    ")\n",
    "\n",
    "print(f'Train\\t| X shape: {x_train.shape}\\tY shape: {y_train.shape}')\n",
    "print(f'Test\\t| X shape: {x_test.shape}\\tY shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29fbe5",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d18517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features = MAX_FEATURES)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectorizer.fit(x_train)\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train).todense()\n",
    "x_test_tfidf = vectorizer.transform(x_test).todense()\n",
    "\n",
    "# Matrix to Array\n",
    "x_train = np.squeeze(np.asarray(x_train_tfidf))\n",
    "x_train = x_train.reshape(-1, 1, x_train_tfidf.shape[1])\n",
    "\n",
    "# Matrix to Array\n",
    "x_test = np.squeeze(np.asarray(x_test_tfidf))\n",
    "x_test = x_test.reshape(-1, 1, x_test_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45e08d",
   "metadata": {},
   "source": [
    "# Model RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1135a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x_train_c, y_train_c, x_test_c, y_test_c):\n",
    "    rnn = Sequential()\n",
    "    rnn.add(SimpleRNN(units=256, activation='relu', recurrent_dropout=0.2, return_sequences=True))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    rnn.add(SimpleRNN(units=128, activation='relu', return_sequences=True))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    rnn.add(SimpleRNN(units=64, activation='relu'))\n",
    "    rnn.add(Dropout(0.2))\n",
    "    rnn.add(Dense(units=3, activation='softmax'))\n",
    "    \n",
    "    rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    rnn.build(x_train_c.shape)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', mode = 'min', verbose = 1, patience=3, min_delta=0.0001)\n",
    "    model_checkpoint = ModelCheckpoint('rnn_tfidf_akting.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)\n",
    "    \n",
    "    history = rnn.fit(x_train_c, y_train_c, epochs= 10, batch_size=128, \n",
    "                      validation_data=(x_test_c, y_test_c), verbose = 1,\n",
    "                      callbacks=[early_stopping, model_checkpoint])\n",
    "    \n",
    "    model = load_model('rnn_tfidf_akting.h5')\n",
    "    y_pred = model.predict(x_test_c)\n",
    "    y_pred_cat = y_pred.argmax(axis=1)\n",
    "    y_test_cat = np.argmax(y_test_c, axis=1)\n",
    "   \n",
    "    cm = confusion_matrix(y_test_cat, y_pred_cat)\n",
    "    classreport = classification_report(y_test_cat, y_pred_cat)\n",
    "    f1 = f1_score(y_test_cat, y_pred_cat,  average=\"macro\")\n",
    "    recall = recall_score(y_test_cat, y_pred_cat, average=\"macro\")\n",
    "    precision = precision_score(y_test_cat, y_pred_cat, average=\"macro\")\n",
    "    accuracy = accuracy_score(y_test_cat, y_pred_cat)\n",
    "\n",
    "    print(classreport)\n",
    "    print(\"F1 Score : \", f1)\n",
    "    print(\"Precision : \", precision)\n",
    "    print(\"Recall : \", recall)\n",
    "    print(\"Accuracy : \", accuracy)\n",
    "\n",
    "    return [f1, precision, recall, accuracy, cm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d00b03",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1c419c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.61 GiB for an array with shape (12072, 1, 124639) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m hasil \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     hasil\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m+\u001b[39m \u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mRNN\u001b[1;34m(x_train_c, y_train_c, x_test_c, y_test_c)\u001b[0m\n\u001b[0;32m     15\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m     16\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn_tfidf_akting.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_c\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn_tfidf_akting.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test_c)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\TA_Code\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\TA_Code\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.61 GiB for an array with shape (12072, 1, 124639) and data type float32"
     ]
    }
   ],
   "source": [
    "hasil = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    hasil.append([str(i)] + RNN(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca41e89",
   "metadata": {},
   "source": [
    "# Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hasil, columns =['iterasi', 'f1', 'precision', 'recall', 'accuracy', 'cm'])\n",
    "#df.to_excel('rnn_tfidf_akting.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d08f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : %.2f\" % (df['accuracy'].mean()*100))\n",
    "print(\"F1-Score : %.2f\" % (df['f1'].mean()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
